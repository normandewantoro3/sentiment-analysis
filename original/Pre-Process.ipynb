{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nlp_id.stopword import StopWord \n",
    "from nlp_id.postag import PosTag\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import torch\n",
    "from nlp_id.lemmatizer import Lemmatizer \n",
    "from googletrans import Translator\n",
    "import regex\n",
    "from fuzzysearch import find_near_matches\n",
    "import datetime\n",
    "from multiprocessing import  Pool\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pandarallel import pandarallel\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Names Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"news.csv\")\n",
    "topics = [\"Business\", \"investasi\", \"market\", \n",
    "          \"Tech\", \"teknologi\", \"stocksetup\", \n",
    "          \"Business\", \"Finance\", \"IT and Telco\", \"TEKNO\",\n",
    "          \"finansial\", \"investasi\", \"keuangan\", \"telkomindonesia\", \"Market\"]\n",
    "full_df = raw.loc[raw[\"topic\"].isin(topics), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_excel(\"Stock_Names.xlsx\", usecols = [\"Ticker\", \"Nama\"], keep_default_na = False)\n",
    "\n",
    "\n",
    "stock_names = stocks.iloc[:,1]\n",
    "tickers = stocks.iloc[:,0]\n",
    "zip_iterator = zip(tickers, stock_names)\n",
    "stock_dict = dict(zip_iterator)\n",
    "stock_dict[\"TRUE\"] = stock_dict.pop(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_ticker_title(text):\n",
    "    res = []\n",
    "    for names in stock_dict:\n",
    "            test_title_full = find_near_matches(stock_dict[names], text, max_l_dist=1)\n",
    "        #### Depan space or blkng non text character \n",
    "            pattern = r\"\\b{temp}\\b\".format(temp = names)\n",
    "            test_title_ticker = re.search(pattern, text)\n",
    "            if test_title_full:\n",
    "                res.append(names)\n",
    "            elif test_title_ticker:\n",
    "                res.append(names) \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ad2998006b4ae9852107d040aca845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=75502), Label(value='0 / 75502')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar = True)\n",
    "\n",
    "ticker_title = full_df[\"title\"].apply(str).parallel_apply(search_ticker_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_stock = {\"BBCA\": r\"\\bBCA\\b\",\n",
    "             \"BBRI\": r\"\\bBRI\\b(?! Syariah| Agroniaga)\",\n",
    "             \"AGRO\": r\"\\bBRI Agroniaga\\b\",\n",
    "             \"BBNI\": r\"\\bBNI (?! Syariah)\\b\",\n",
    "             \"BRIS\": r\"\\bBRI Syariah\\b\",\n",
    "             \"ANTM\": r\"\\bAntam\\b\",\n",
    "             \"AASI\": r\"\\bAstra\\b(?! Otoparts| Graphia| Agro)\",\n",
    "             \"TLKM\": r\"\\bTelkom\",\n",
    "             \"BMRI\": r\"\\bMandiri\\b\",\n",
    "             \"SMRA\": r\"\\bSumarecon\\b\",\n",
    "             \"BNII\": r\"\\bMaybank\\b\",\n",
    "             \"PWON\": r\"\\bPakuwon\\b\",\n",
    "             \"MNCN\": r\"\\bMNCN\\b\",\n",
    "             \"UNVR\": r\"\\bUnilever\\b\",\n",
    "             \"AKRA\": r\"\\bAKR\\b\",\n",
    "             \"MAYA\": r\"\\bMayapada\\b\",\n",
    "             \"INTP\": r\"\\bIndocement\\b\",\n",
    "             \"BDMN\": r\"\\bDanamon\\b\",\n",
    "             \"BNBR\": r\"\\bBakrie and Brothers\\b\",\n",
    "             \"BANK\": r\"\\bBank Aladin\\b\",\n",
    "             \"BBTN\": r\"\\bBTN\\b\",\n",
    "             \"LIFE\": r\"\\b(Sinarmas MSIG Life|Sinarmas Life)\\b\",\n",
    "             \"EXCL\": r\"\\bXL\\b\",\n",
    "             \"BNGA\": r\"\\bCIMB Niaga\\b\",\n",
    "             \"PNBN\": r\"\\bPanin\\b(?! Syariah)\",\n",
    "             \"SMGR\": r\"\\bSemen Gresik\\b\",\n",
    "             \"ACES\": r\"\\bAce Hardware\\b\",\n",
    "             \"IMAS\": r\"\\bIndomobil\\b\"}\n",
    "def find_alternative(text):\n",
    "    res = []\n",
    "    for names in alt_stock:\n",
    "            test_title_ticker = re.search(alt_stock[names], text)\n",
    "            if test_title_ticker:\n",
    "                res.append(names)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c48ae3f2a6e4974b256a05788462758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=75502), Label(value='0 / 75502')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alt_ticker_title = full_df[\"title\"].apply(str).parallel_apply(find_alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(first_list, second_list):\n",
    "    return first_list + list(set(second_list) - set(first_list))\n",
    "\n",
    "ticker_df = pd.DataFrame({\"Original\" : ticker_title, \"Alternative\": alt_ticker_title})\n",
    "\n",
    "combined_ticker = ticker_df.apply(lambda x: combine(x[\"Original\"], x[\"Alternative\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_one = lambda x: len(x) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_idx = combined_ticker[combined_ticker.apply(more_than_one)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r add_trans merged translated_cleaned\n",
    "\n",
    "past_trans = pd.concat([add_trans, merged, translated_cleaned]).drop_duplicates(keep = \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140524"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(past_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text_en(text, key):\n",
    "    import os\n",
    "\n",
    "    # Set environment variables\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = key\n",
    "    \n",
    "    import six\n",
    "    \n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    result = translate_client.translate(text, target_language= \"en\")\n",
    "    \n",
    "    return result[\"translatedText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ticker_trans = full_df \\\n",
    "                .merge(ticker_idx.rename(\"Ticker\"), how = \"right\", left_index = True, right_index = True) \\\n",
    "                .merge(past_trans.rename(\"Translation\"), how = \"left\", right_index = True, left_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_title_idx = title_ticker_trans[\"Translation\"].isna()\n",
    "new_title = title_ticker_trans[\"title\"][new_title_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151006"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_ticker_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37184"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140524"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(past_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_title_trans = np.array_split(new_title, 10)\n",
    "new0 = new_title_trans[0]\n",
    "new1 = new_title_trans[1]\n",
    "new2 = new_title_trans[2]\n",
    "new3 = new_title_trans[3]\n",
    "new4 = new_title_trans[4]\n",
    "new5 = new_title_trans[5]\n",
    "new6 = new_title_trans[6]\n",
    "new7 = new_title_trans[7]\n",
    "new8 = new_title_trans[8]\n",
    "new9 = new_title_trans[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_text_en(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4800c1a402fe453aa41cff292b98ddd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=465), Label(value='0 / 465'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-34:\n",
      "Process ForkPoolWorker-35:\n",
      "Process ForkPoolWorker-33:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar = True)\n",
    "\n",
    "trans0 = new0.apply(str).parallel_apply(translate_text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans1 = new1.apply(str).parallel_apply(translate_text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans2 = new2.apply(str).parallel_apply(translate_text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans3 = new3.apply(str).parallel_apply(translate_text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans4 = new4.apply(str).parallel_apply(translate_text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans5 = new5.apply(str).parallel_apply(translate_text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans6 = new6.apply(str).parallel_apply(translate_text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans7 = new7.apply(str).parallel_apply(translate_text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans8 = new8.apply(str).parallel_apply(translate_text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans9 = new9.apply(str).parallel_apply(translate_text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_new_trans = pd.concat([trans0,\n",
    "                           trans1,\n",
    "                           trans2,\n",
    "                           trans3,\n",
    "                           trans4,\n",
    "                           trans5,\n",
    "                           trans6,\n",
    "                           trans7,\n",
    "                           trans8,\n",
    "                           trans9])\n",
    "all_new_trans = pd.concat([past_trans, all_new_trans]).apply(html.unescape).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(all_new_trans.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df1 = full_df \\\n",
    "            .merge(ticker_idx.rename(\"Ticker\"), how = \"right\", left_index = True, right_index = True) \\\n",
    "            .merge(all_new_trans.rename(\"Translation\"), how = \"left\", right_index = True, left_index = True)\n",
    "%store final_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ad-Hoc Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manual Change\n",
    "def clean_ticker(title, ticker):\n",
    "    res = ticker.copy()\n",
    "    if \"BANK\" in ticker:\n",
    "        if not (re.search(r\"\\bbank aladin\\b\", title.lower()) or re.search(r\"\\bbank net\\b\", title.lower()) or re.search(r\"-BANK-\", title)):\n",
    "            res.remove(\"BANK\")     \n",
    "                \n",
    "    if (\"WTON\" in res and \"WIKA\" in res):\n",
    "        if not(re.search(r\"\\bwijaya karya\\b(?! beton| bangunan)\", title.lower()) or re.search(r\"\\bwika\\b(?! beton| bangunan)\", title.lower())):\n",
    "            res.remove(\"WIKA\")\n",
    "            \n",
    "    if (\"WEGE\" in res and \"WIKA\" in res):\n",
    "        if not(re.search(r\"\\bwijaya karya\\b(?! beton| bangunan)\", title.lower()) or re.search(r\"\\bwika\\b(?! beton| bangunan)\", title.lower())):\n",
    "            res.remove(\"WIKA\")\n",
    "            \n",
    "    if (\"DPNS\" in res and \"DUTI\" in res):\n",
    "        if not(re.search(r\"\\bduta pertiwi\\b(?! nusantara)\", title.lower()) or re.search(r\"\\bDUTI\\b\", title)):\n",
    "            res.remove(\"DUTI\")\n",
    "            \n",
    "    if (\"BRMS\" in res and \"BUMI\" in res):\n",
    "        if not(re.search(r\"\\bbumi resources\\b(?! minerals| mineral)\", title.lower()) or re.search(r\"\\bBUMI\\b\", title)):\n",
    "            res.remove(\"BUMI\")\n",
    "\n",
    "    if (\"BTPN\" in res and \"BBTN\" in res):\n",
    "        if not(re.search(r\"\\bbank btpn\\b\", title.lower()) or re.search(r\"\\bBTPN\\b\", title)):\n",
    "            res.remove(\"BTPN\")\n",
    "\n",
    "    if (\"PNBN\" in res and \"PNBS\" in res):\n",
    "        if not(re.search(r\"\\bbank panin\\b(?! syariah)\", title.lower()) or re.search(r\"\\bPNBN\\b\", title)):\n",
    "            res.remove(\"PNBN\")\n",
    "            \n",
    "    if (\"BLUE\" in res and \"BIRD\" in res):\n",
    "        if (re.search(r\"\\bBLUE BIRD\\b\")):\n",
    "            res.remove(\"BLUE\")\n",
    "    \n",
    "    if \"INDO\" in res:\n",
    "        res.remove(\"INDO\")\n",
    "    if \"CITY\" in res:\n",
    "        res.remove(\"CITY\")\n",
    "    if \"LABA\" in res:\n",
    "        res.remove(\"LABA\")\n",
    "    if \"AKSI\" in res:\n",
    "        res.remove(\"AKSI\")\n",
    "    if \"LAND\" in res:\n",
    "        res.remove(\"LAND\")\n",
    "    \n",
    "    if \"BINA\" in res:\n",
    "        res.remove(\"BIMA\")\n",
    "    if \"CASH\" in res:\n",
    "        res.remove(\"CASH\")\n",
    "    if \"AMAN\" in res:\n",
    "        res.remove(\"AMAN\")\n",
    "    if \"BALI\" in ticker:\n",
    "        res.remove(\"BALI\")\n",
    "    \n",
    "    if \"CARE\" in res:\n",
    "        res.remove(\"CARE\")\n",
    "    if \"DAYA\" in res:\n",
    "        res.remove(\"DAYA\")\n",
    "    if \"BUDI\" in res:\n",
    "        res.remove(\"BUDI\")\n",
    "    if \"BALI\" in ticker:\n",
    "        res.remove(\"BALI\")\n",
    "    \n",
    "    if \"FOOD\" in res:\n",
    "        res.remove(\"FOOD\")\n",
    "    if \"LIFE\" in res:\n",
    "        res.remove(\"LIFE\")\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ticker = final_df1.apply(lambda x: clean_ticker(x[\"title\"], x[\"Ticker\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df1 = pd.read_csv(\"coba_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "final_df1[\"Final Ticker\"] = final_df1[\"Cleaned Ticker\"].apply(ast.literal_eval)\n",
    "final_df1[\"Final Ticker\"] = final_df1.apply(lambda x: final_tweak(x[\"Final Ticker\"], x[\"title\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>tag</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>...</th>\n",
       "      <th>Cleaned Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Final Ticker</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Trading Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, title, topic, tag, date, url, language, source, text, Ticker, Translation, Cleaned Ticker, Date, Time, Year, Month, Day, Hour, Final Ticker, Datetime, Trading Date]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df1[final_df1[\"Final Ticker\"] == \"NASA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Trading Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df1[\"Datetime\"] = pd.to_datetime(final_df1[\"date\"])\n",
    "\n",
    "\n",
    "final_df1[\"Date\"] = final_df1[\"Datetime\"].apply(lambda text: text.date())\n",
    "final_df1[\"Time\"] = final_df1[\"Datetime\"].apply(lambda text: text.time())\n",
    "final_df1[\"Year\"] = final_df1[\"Datetime\"].apply(lambda text: text.year)\n",
    "final_df1[\"Month\"] = final_df1[\"Datetime\"].apply(lambda text: text.month)\n",
    "final_df1[\"Day\"] = final_df1[\"Datetime\"].apply(lambda text: text.day)\n",
    "final_df1[\"Hour\"] = final_df1[\"Datetime\"].apply(lambda text: text.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_stock = pd.read_csv(\"PX_LAST20020101.csv\")\n",
    "price_stock[\"Date\"] = pd.to_datetime(price_stock[\"Date\"], format = \"%Y%m%d\")\n",
    "price_stock = price_stock.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_date(date_time):\n",
    "    date = price_stock.index.tolist()\n",
    "    next_date = date_time + datetime.timedelta(days = 1)\n",
    "    while next_date not in date:\n",
    "        next_date += datetime.timedelta(days = 1)\n",
    "    return next_date\n",
    "\n",
    "def get_tdate(date_time, hour):\n",
    "    # Check if date is before trading hour\n",
    "    # Check next period is in business day\n",
    "    # If in business date use according to the original rule\n",
    "    # If not use the\n",
    "    date = price_stock.index.tolist()\n",
    "    if hour <= 8:\n",
    "        if date_time in date:\n",
    "            return date_time\n",
    "        else:\n",
    "            return find_next_date(date_time)\n",
    "    else:\n",
    "        return find_next_date(date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3596ef8a481486b8c62e0d0c845e513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=18876), Label(value='0 / 18876')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_df1[\"Trading Date\"] = final_df1.parallel_apply(lambda x: get_tdate(x[\"Date\"], x[\"Hour\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_tweak(ticker , title):\n",
    "    res = ticker.copy()\n",
    "    if \"AASI\" in res:\n",
    "        res.remove(\"AASI\")\n",
    "        res.append(\"ASII\")\n",
    "    if \"LIFE\" in res:\n",
    "        res.remove(\"LIFE\")\n",
    "    if \"NASA\" in res:\n",
    "        res.remove(\"NASA\")\n",
    "    if \"WIKA\" in res:\n",
    "        if re.search(r\"\\bwika gedung\\b\", title.lower()):\n",
    "            res.remove(\"WIKA\")\n",
    "            res.append(\"WEGE\")\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Rows with more than 1 Stock Name Mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_idx = final_df1[\"Final Ticker\"].apply(lambda x: len(x) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2 = final_df1[one_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-308b23a054d3>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df2[\"Final Ticker\"] = final_df2[\"Final Ticker\"].apply(lambda x: x[0])\n"
     ]
    }
   ],
   "source": [
    "final_df2[\"Final Ticker\"] = final_df2[\"Final Ticker\"].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2 = final_df2.set_index(\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Rows Under IDR 1 T Market Cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap = pd.read_csv(\"MKT_CAP 20020101.csv\")\n",
    "market_cap[\"Date\"] = pd.to_datetime(market_cap[\"Date\"], format = \"%Y%m%d\")\n",
    "market_cap = market_cap.set_index(\"Date\")\n",
    "\n",
    "risk_free = pd.read_csv(\"risk_free.csv\")\n",
    "risk_free[\"Date\"] = pd.to_datetime(risk_free[\"Date\"], format = \"%Y%m%d\")\n",
    "\n",
    "def get_market_cap(row):\n",
    "    ticker_name = row[\"Final Ticker\"]\n",
    "    date = row[\"Trading Date\"]\n",
    "    res = market_cap.loc[str(date), ticker_name]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_names = market_cap.columns\n",
    "final_df3 = final_df2[final_df2[\"Final Ticker\"].isin(stock_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap_df = final_df3.apply(get_market_cap, axis = 1)\n",
    "idx_mrktcap = market_cap_df >= 10^12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_df = final_df3[idx_mrktcap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127779"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sliced_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Unused Columns and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df3.drop([\"date\", \"Ticker\", \"Cleaned Ticker\"], axis = 1).to_csv(\"full_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_df.drop([\"date\", \"Ticker\", \"Cleaned Ticker\"], axis = 1).to_csv(\"marketcap_df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
